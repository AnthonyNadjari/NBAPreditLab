"""
NBA Predictor - Enhanced Interface
Full-featured: Predictions, Portfolio Tracking, Analytics, Performance
"""

import streamlit as st
import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sqlite3
import time
import json
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Check for required dependencies
try:
    from src.predictor import NBAPredictor
    from src.data_fetcher import NBADataFetcher, FeatureEngineer, EloRatingSystem
    from src.odds_scraper import generate_bookmaker_odds, odds_to_american
    from src.model_feedback_system import ModelFeedbackSystem
    from src.injury_tracker import InjuryTracker
    from nba_api.stats.static import teams
    DEPS_OK = True
except ImportError as e:
    DEPS_OK = False
    IMPORT_ERR = str(e)

# Page config
st.set_page_config(page_title="NBA Predictor", page_icon="üèÄ", layout="wide", initial_sidebar_state="expanded")

# =============================================================================
# CSS - Compact & Clean
# =============================================================================
st.markdown("""
<style>
    .main {background: #f8fafc;}
    .block-container {max-width: 1400px; padding: 0.5rem 1rem;}
    h1 {font-size: 1.4rem !important; font-weight: 800 !important; color: #0f172a !important;}
    h2 {font-size: 1.1rem !important; font-weight: 700 !important; color: #1e293b !important;}
    h3 {font-size: 0.95rem !important; font-weight: 600 !important; color: #334155 !important;}

    /* Fix tab styling */
    .stTabs [data-baseweb="tab-list"] {gap: 4px; background-color: transparent;}
    .stTabs [data-baseweb="tab"] {
        background-color: #e2e8f0;
        border-radius: 6px 6px 0 0;
        padding: 8px 16px;
        color: #475569;
        font-size: 0.9rem;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1e3a5f !important;
        color: white !important;
    }
    .stTabs [data-baseweb="tab-panel"] {background-color: transparent; padding-top: 1rem;}

    /* Selectbox styling - remove blue highlight */
    .stSelectbox > div > div {
        background-color: white !important;
        border: 1px solid #cbd5e1 !important;
    }
    .stSelectbox [data-baseweb="select"] > div {
        background-color: white !important;
    }

    .game-card {
        background: white;
        border-radius: 10px;
        padding: 1.25rem;
        margin: 0.75rem 0;
        box-shadow: 0 1px 8px rgba(0,0,0,0.05);
        border: 1px solid #e2e8f0;
    }

    .stat-box {
        background: white;
        border-radius: 8px;
        padding: 0.75rem;
        text-align: center;
        box-shadow: 0 1px 3px rgba(0,0,0,0.03);
        border: 1px solid #e2e8f0;
    }
    .stat-value {font-size: 1.4rem; font-weight: 700; color: #0f172a;}
    .stat-label {font-size: 0.7rem; color: #64748b; text-transform: uppercase;}
    .stat-value.green {color: #059669;}
    .stat-value.blue {color: #2563eb;}
    .stat-value.orange {color: #d97706;}

    .factor-home {
        background: linear-gradient(90deg, #f0fdf4 0%, white 100%);
        border-left: 3px solid #22c55e;
        border-radius: 0 6px 6px 0;
        padding: 0.5rem 0.75rem;
        margin: 0.3rem 0;
    }
    .factor-away {
        background: linear-gradient(90deg, #fef2f2 0%, white 100%);
        border-left: 3px solid #ef4444;
        border-radius: 0 6px 6px 0;
        padding: 0.5rem 0.75rem;
        margin: 0.3rem 0;
    }
    .factor-text {font-weight: 600; color: #1e293b; font-size: 0.85rem;}
    .factor-impact {font-size: 0.7rem; color: #64748b;}

    .conf-high {background: #dcfce7; color: #166534; padding: 3px 10px; border-radius: 15px; font-size: 0.75rem; font-weight: 600;}
    .conf-med {background: #fef3c7; color: #92400e; padding: 3px 10px; border-radius: 15px; font-size: 0.75rem; font-weight: 600;}
    .conf-low {background: #fee2e2; color: #991b1b; padding: 3px 10px; border-radius: 15px; font-size: 0.75rem; font-weight: 600;}

    .portfolio-card {
        background: linear-gradient(135deg, #059669 0%, #047857 100%);
        border-radius: 10px;
        padding: 1rem;
        color: white;
        margin-bottom: 0.75rem;
    }
    .portfolio-loss {background: linear-gradient(135deg, #dc2626 0%, #b91c1c 100%);}

    /* Hide streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}

    .stButton>button {
        background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        font-size: 0.85rem;
    }

    .parlay-info {
        background: #eff6ff;
        border: 1px solid #bfdbfe;
        border-radius: 6px;
        padding: 0.75rem;
        margin: 0.5rem 0;
        font-size: 0.85rem;
    }

    /* Compact sidebar */
    section[data-testid="stSidebar"] {
        width: 280px !important;
    }
    section[data-testid="stSidebar"] .block-container {
        padding: 1rem !important;
    }
    
    /* Improve expander behavior - prevent auto-scroll to bottom */
    .streamlit-expanderHeader {
        scroll-margin-top: 80px;
    }
    .streamlit-expanderContent {
        scroll-margin-top: 80px;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================
def safe_rerun():
    """Rerun the app - compatible with different Streamlit versions"""
    try:
        st.rerun()
    except AttributeError:
        try:
            st.experimental_rerun()
        except:
            pass  # Silent fail - page will update on next interaction

def safe_dataframe(df, **kwargs):
    """Display dataframe compatible with all Streamlit versions"""
    try:
        st.dataframe(df, use_container_width=True, **kwargs)
    except TypeError:
        try:
            st.dataframe(df, **kwargs)
        except:
            st.table(df)

def safe_plotly_chart(fig, **kwargs):
    """Display plotly chart compatible with all Streamlit versions"""
    try:
        st.plotly_chart(fig, use_container_width=True, **kwargs)
    except TypeError:
        try:
            st.plotly_chart(fig, **kwargs)
        except:
            st.write("Chart display error - please upgrade Streamlit")

# =============================================================================
# CONSTANTS
# =============================================================================
RELIABLE_BOOKMAKERS = ['Pinnacle', 'Bet365', 'DraftKings']

# =============================================================================
# DATABASE HELPER FUNCTIONS
# =============================================================================
def init_database(db_path: str):
    """Initialize all database tables"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS portfolio (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            bet_type TEXT,
            games TEXT,
            stake REAL,
            potential_payout REAL,
            combined_odds REAL,
            status TEXT DEFAULT 'pending',
            actual_payout REAL DEFAULT 0,
            settled_at TIMESTAMP
        )
    """)

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS user_balance (
            id INTEGER PRIMARY KEY CHECK (id = 1),
            balance REAL DEFAULT 1000.0,
            total_wagered REAL DEFAULT 0,
            total_won REAL DEFAULT 0,
            total_lost REAL DEFAULT 0,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    cursor.execute("INSERT OR IGNORE INTO user_balance (id, balance) VALUES (1, 1000.0)")

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS predictions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            prediction_date TEXT,
            game_date TEXT,
            game_id TEXT,
            home_team TEXT,
            away_team TEXT,
            predicted_winner TEXT,
            predicted_home_prob REAL,
            predicted_away_prob REAL,
            confidence REAL,
            actual_winner TEXT,
            actual_home_score INTEGER,
            actual_away_score INTEGER,
            correct INTEGER,
            prediction_error REAL,
            calibration_error REAL,
            features_json TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # Add missing columns for existing DBs
    for col in ['prediction_error REAL', 'calibration_error REAL', 'features_json TEXT']:
        try:
            cursor.execute(f"ALTER TABLE predictions ADD COLUMN {col}")
        except:
            pass

    conn.commit()
    conn.close()

def get_user_balance(db_path):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT balance, total_wagered, total_won, total_lost FROM user_balance WHERE id = 1")
    row = cursor.fetchone()
    conn.close()
    return {'balance': row[0], 'wagered': row[1], 'won': row[2], 'lost': row[3]} if row else {'balance': 1000.0, 'wagered': 0, 'won': 0, 'lost': 0}

def update_user_balance(db_path, amount, bet_type='wager'):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    if bet_type == 'wager':
        cursor.execute("UPDATE user_balance SET balance = balance - ?, total_wagered = total_wagered + ? WHERE id = 1", (amount, amount))
    elif bet_type == 'win':
        cursor.execute("UPDATE user_balance SET balance = balance + ?, total_won = total_won + ? WHERE id = 1", (amount, amount))
    elif bet_type == 'reset':
        cursor.execute("UPDATE user_balance SET balance = 1000.0, total_wagered = 0, total_won = 0, total_lost = 0 WHERE id = 1")
    conn.commit()
    conn.close()

def place_bet(db_path, games_info, stake, combined_odds, bet_type='single'):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO portfolio (bet_type, games, stake, potential_payout, combined_odds, status)
        VALUES (?, ?, ?, ?, ?, 'pending')
    """, (bet_type, json.dumps(games_info), stake, stake * combined_odds, combined_odds))
    conn.commit()
    conn.close()
    update_user_balance(db_path, stake, 'wager')

def get_portfolio_history(db_path):
    conn = sqlite3.connect(db_path)
    df = pd.read_sql_query("SELECT * FROM portfolio ORDER BY created_at DESC LIMIT 50", conn)
    conn.close()
    return df

def convert_numpy_types(obj):
    """
    Recursively convert numpy types to native Python types for JSON serialization.
    Handles numpy int64, float64, int32, float32, bool_, ndarray, etc.
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, (pd.Timestamp, datetime)):
        return obj.isoformat() if hasattr(obj, 'isoformat') else str(obj)
    else:
        return obj

def save_prediction_to_db(db_path, prediction_data):
    """Save or update prediction in database"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # Convert features to JSON-safe format
    features = prediction_data.get('features', {})
    try:
        # Convert numpy types to native Python types
        features_converted = convert_numpy_types(features)
        features_json = json.dumps(features_converted)
    except (TypeError, ValueError) as e:
        print(f"‚ö†Ô∏è Error serializing features to JSON: {e}")
        # If serialization fails, save empty dict but log the error
        features_json = json.dumps({})
        print(f"   Saving prediction without features. Feature types: {[type(v).__name__ for v in list(features.values())[:5]]}")

    # Use INSERT OR REPLACE to handle duplicates
    try:
        cursor.execute("""
            INSERT OR REPLACE INTO predictions (
                prediction_date, game_date, home_team, away_team,
                predicted_winner, predicted_home_prob, predicted_away_prob,
                confidence, features_json
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            prediction_data['game_date'],
            prediction_data['home_team'],
            prediction_data['away_team'],
            prediction_data['predicted_winner'],
            float(prediction_data['predicted_home_prob']),
            float(prediction_data['predicted_away_prob']),
            float(prediction_data['confidence']),
            features_json
        ))
        conn.commit()
    except Exception as e:
        conn.rollback()
        print(f"‚ùå Error saving prediction to database: {e}")
        raise
    finally:
        conn.close()

# =============================================================================
# SETUP
# =============================================================================
if not DEPS_OK:
    st.error(f"Missing dependencies: {IMPORT_ERR}")
    st.stop()

NBA_TEAMS = sorted([team['full_name'] for team in teams.get_teams()])
TEAM_IDS = {team['full_name']: team['id'] for team in teams.get_teams()}
ID_TO_TEAM = {team['id']: team['full_name'] for team in teams.get_teams()}
db_path = project_root / "data" / "nba_predictor.db"
models_path = project_root / "models"

init_database(str(db_path))

if 'predictor' not in st.session_state:
    st.session_state.predictor = NBAPredictor(db_path=str(db_path), model_dir=str(models_path))
if 'todays_predictions' not in st.session_state:
    st.session_state.todays_predictions = None
if 'selected_bets' not in st.session_state:
    st.session_state.selected_bets = []

def get_conf_badge(conf):
    if conf >= 0.7: return "High", "conf-high"
    if conf >= 0.55: return "Medium", "conf-med"
    return "Low", "conf-low"

# =============================================================================
# VISUALIZATION FUNCTIONS
# =============================================================================
def create_feature_importance_chart(top_factors, home_team, away_team):
    if not top_factors:
        return None

    features, impacts, colors, impact_pct = [], [], [], []
    for factor in top_factors[:10]:
        nn = factor['feature'].replace('_', ' ').replace('home ', '').replace('away ', '').title()
        nn = nn.replace('Last10', 'L10').replace('Last5', 'L5').replace('Pct', '%')
        features.append(nn)
        impact_val = factor['impact']
        impacts.append(impact_val)
        # Convert to percentage impact on win probability
        impact_pct.append(abs(impact_val) * 100)
        colors.append('#22c55e' if impact_val > 0 else '#ef4444')

    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=features, 
        x=impacts, 
        orientation='h', 
        marker_color=colors,
        text=[f"{abs(i)*100:.2f}%" for i in impacts], 
        textposition='outside',
        hovertemplate='<b>%{y}</b><br>Impact: %{text} on win probability<extra></extra>'
    ))
    fig.update_layout(
        title=f"Top Feature Impacts<br><sub>Values show change in home win probability (scale: ¬±{max(impact_pct):.2f}%)</sub>",
        xaxis_title="Impact on Win Probability (%)",
        yaxis_title="",
        height=400,
        showlegend=False,
        xaxis=dict(
            zeroline=True,
            zerolinewidth=2,
            zerolinecolor='#cbd5e1',
            gridcolor='#f1f5f9',
            tickformat='.1%'
        ),
        plot_bgcolor='white',
        margin=dict(l=20, r=20, t=80, b=40)
    )
    return fig

def create_feature_radar_chart(features, home_team, away_team):
    """
    Create radar chart with ADVANCED METRICS (no PPG!)
    Shows: Win%, Off Rating, Def Rating, 3P%, Rebounds, Elo
    """
    if not features:
        return None

    categories = ['Win %', 'Off Rtg', 'Def Rtg', '3P%', 'Rebounds', 'Elo']
    home_values = [
        features.get('home_last10_win_pct', 0.5) * 100,
        (features.get('home_last10_offensive_rating', 110) - 90) / 0.4,  # Normalize 90-130 to 0-100
        100 - ((features.get('home_last10_defensive_rating', 110) - 90) / 0.4),  # Lower is better, so invert
        features.get('home_last10_fg3_pct', 0.35) * 250,  # Normalize ~0.35 to ~87
        features.get('home_last10_reb', 44),
        (features.get('home_elo', 1500) - 1400) / 3
    ]
    away_values = [
        features.get('away_last10_win_pct', 0.5) * 100,
        (features.get('away_last10_offensive_rating', 110) - 90) / 0.4,
        100 - ((features.get('away_last10_defensive_rating', 110) - 90) / 0.4),
        features.get('away_last10_fg3_pct', 0.35) * 250,
        features.get('away_last10_reb', 44),
        (features.get('away_elo', 1500) - 1400) / 3
    ]

    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(r=home_values, theta=categories, fill='toself', name=home_team, line_color='#22c55e'))
    fig.add_trace(go.Scatterpolar(r=away_values, theta=categories, fill='toself', name=away_team, line_color='#ef4444'))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=True, height=350)
    return fig

# =============================================================================
# SIDEBAR - Compact
# =============================================================================
with st.sidebar:
    st.markdown("### üèÄ NBA Predictor")

    balance_info = get_user_balance(str(db_path))
    st.markdown(f"""
    <div class="portfolio-card">
        <div style="font-size: 0.8rem; opacity: 0.8;">Balance</div>
        <div style="font-size: 1.5rem; font-weight: 800;">${balance_info['balance']:,.2f}</div>
    </div>
    """, unsafe_allow_html=True)

    profit = balance_info['won'] - balance_info['lost']
    c1, c2 = st.columns(2)
    c1.metric("Wagered", f"${balance_info['wagered']:,.0f}")
    c2.metric("P/L", f"${profit:+,.0f}")

    st.markdown("---")
    
    # =============================================================================
    # HELP SECTION - Metric Definitions
    # =============================================================================
    with st.expander("üìä Metric Definitions", expanded=False):
        st.markdown("""
        **Win Probability**: The model's estimated chance (0-100%) that the home team will win this game.

        **Confidence Level**:
        - **High (‚â•70%)**: Model strongly agrees across all base models, prediction is far from 50/50
        - **Medium (55-69%)**: Moderate agreement, some uncertainty
        - **Low (<55%)**: Low agreement between models, close to coin flip

        **Feature Impact**: Shows how much each feature changes the predicted win probability.
        Values like 0.006 mean a 0.6% shift in win probability - small individual impacts add up.

        **Model Consensus**: Individual predictions from each base model (XGBoost, LightGBM, Random Forest, Logistic Regression).
        When all models agree, confidence is higher.
        """)

        st.markdown("---")
        st.markdown("### üìà Understanding Feature Impact")
        st.markdown("""
        - **Impact Value**: Shows how much each feature changes the predicted win probability
        - **Scale**: Small values (0.002-0.006 = 0.2%-0.6%) are normal - many features contribute, and their combined effect determines the prediction
        - **Positive Values**: Favor the home team winning (green bars)
        - **Negative Values**: Favor the away team winning (red bars)
        - **Why Small?**: With 100+ features, each contributes a small amount. A single feature changing win probability by 1-2% is significant when combined with others
        """)

    with st.expander("üìö Feature Definitions & Categories", expanded=False):
        st.markdown("""
        **1. Elo Ratings**
        - **Elo Rating**: Team strength rating (1500 = average). Higher = stronger team
        - **Elo Difference**: Home Elo - Away Elo. Positive = home team advantage
        - **Elo Win Probability**: Expected win probability based purely on Elo ratings
        
        **2. Recent Form (Last 10 Games)**
        - **Win %**: Percentage of games won in last 10
        - **PPG**: Points per game (offensive output)
        - **Opp PPG**: Opponent points per game (defensive quality)
        - **Point Diff**: Average point differential (PPG - Opp PPG)
        - **FG% / 3P% / FT%**: Shooting percentages
        - **Rebounds / Assists / Turnovers**: Key team stats
        
        **3. Recent Form (Last 5 Games)**
        - Same metrics as Last 10, but more recent (captures current momentum)
        
        **4. Home/Away Splits**
        - **Home Win %**: Team's win percentage when playing at home
        - **Road Win %**: Team's win percentage when playing away
        - Teams often perform differently at home vs on the road
        
        **5. Head-to-Head**
        - **H2H Win %**: Historical win percentage between these teams
        - **Last 3 Results**: Recent matchups (psychological factor)
        - **Avg Point Diff**: Average margin in previous matchups
        
        **6. Situational Factors**
        - **Rest Days**: Days since last game (affects fatigue)
        - **Rest Advantage**: Home rest days - Away rest days
        - **Streak**: Current win/loss streak (positive = wins, negative = losses)
        - **Back-to-Back**: Playing on consecutive days (fatigue indicator)
        
        **7. Advanced Metrics**
        - **Net Rating**: Offensive efficiency - Defensive efficiency
        - **TOV Rate**: Turnover rate (lower is better)
        - **Momentum**: Comparison of Last 5 vs Last 10 (improving vs declining)
        
        **8. Player-Level Stats** (when available)
        - **Top Scorer PPG**: Leading scorer's points per game
        - **Top Playmaker APG**: Leading assist man's assists per game
        - **Active Players**: Number of active roster members
        """)

    st.markdown("---")
    st.markdown("#### üé´ Bet Slip")

    if st.session_state.selected_bets:
        combined_odds = 1.0
        for bet in st.session_state.selected_bets:
            combined_odds *= bet['odds']
            st.caption(f"**{bet['team']}** @ {bet['odds']:.2f}")

        if len(st.session_state.selected_bets) > 1:
            st.markdown(f'<div class="parlay-info"><strong>PARLAY</strong> - Combined: {combined_odds:.2f}</div>', unsafe_allow_html=True)

        stake = st.number_input("Stake ($)", min_value=1.0, max_value=float(balance_info['balance']), value=10.0, step=5.0)
        st.caption(f"Potential: **${stake * combined_odds:.2f}**")

        c1, c2 = st.columns(2)
        if c1.button("Place Bet"):
            if stake <= balance_info['balance']:
                games_info = [{'team': b['team'], 'game': b['game'], 'odds': b['odds']} for b in st.session_state.selected_bets]
                place_bet(str(db_path), games_info, stake, combined_odds, 'parlay' if len(st.session_state.selected_bets) > 1 else 'single')
                st.success("Bet placed!")
                st.session_state.selected_bets = []
                safe_rerun()
        if c2.button("Clear"):
            st.session_state.selected_bets = []
            safe_rerun()
    else:
        st.caption("Add bets from Today's Games")

    st.markdown("---")
    if st.button("Reset Balance"):
        update_user_balance(str(db_path), 0, 'reset')
        safe_rerun()

# =============================================================================
# DISPLAY GAME
# =============================================================================
def display_game(pred, expanded=False):
    ht, at = pred['home_team'], pred['away_team']
    winner = ht if pred['prediction'] == 'home' else at
    win_prob = pred['home_win_probability'] if pred['prediction'] == 'home' else pred['away_win_probability']
    conf = pred['confidence']
    conf_text, conf_class = get_conf_badge(conf)
    features = pred.get('features', {})
    odds = generate_bookmaker_odds(pred['home_win_probability'])

    st.markdown(f"""
    <div class="game-card">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <div style="font-size: 1rem; font-weight: 600;">{at} @ {ht}</div>
                <div style="margin-top: 0.3rem;">
                    <span style="color: #059669; font-weight: 700;">{winner}</span>
                    <span style="color: #64748b; margin-left: 0.5rem;">{win_prob:.1%}</span>
                </div>
            </div>
            <div style="text-align: right;">
                <span class="{conf_class}">{conf_text}</span>
                <div style="font-size: 0.8rem; color: #64748b;">{conf:.0%}</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Add tooltip explaining "@" notation
    st.caption(f"üí° **Note**: '{at} @ {ht}' means {at} is playing at {ht}'s home stadium")
    # Note: We don't use expanded=True to prevent auto-scroll to bottom
    with st.expander(f"üìä Details: {at} @ {ht}", expanded=False):
        # Bet buttons
        c1, c2 = st.columns(2)
        home_odds = odds['bookmakers'].get('Pinnacle', {}).get('home', 2.0)
        away_odds = odds['bookmakers'].get('Pinnacle', {}).get('away', 2.0)

        if c1.button(f"Bet {ht} @ {home_odds:.2f}", key=f"h_{ht}_{at}"):
            st.session_state.selected_bets.append({'team': ht, 'game': f"{at} @ {ht}", 'odds': home_odds})
            safe_rerun()
        if c2.button(f"Bet {at} @ {away_odds:.2f}", key=f"a_{ht}_{at}"):
            st.session_state.selected_bets.append({'team': at, 'game': f"{at} @ {ht}", 'odds': away_odds})
            safe_rerun()

        # Odds
        st.markdown("**Odds (Top 3 Books)**")
        oc1, oc2 = st.columns(2)
        with oc1:
            for book in RELIABLE_BOOKMAKERS:
                if book in odds['bookmakers']:
                    st.caption(f"{book}: {odds['bookmakers'][book]['home']:.2f}")
        with oc2:
            for book in RELIABLE_BOOKMAKERS:
                if book in odds['bookmakers']:
                    st.caption(f"{book}: {odds['bookmakers'][book]['away']:.2f}")

        # Metric definitions removed - now in sidebar for all matches
        
        # Metric and Feature definitions removed - now in sidebar for all matches
        
        # Charts
        if 'top_factors' in pred and pred['top_factors']:
            st.markdown("### üìà Feature Impact Analysis")
            # Explanation removed - now in sidebar for all matches
            fig = create_feature_importance_chart(pred['top_factors'], ht, at)
            if fig:
                safe_plotly_chart(fig)
            
            # Show detailed breakdown of top factors
            st.markdown("#### üîç Top Features Breakdown")
            top_factors_df = pd.DataFrame(pred['top_factors'][:10])
            top_factors_df['Feature'] = top_factors_df['feature'].apply(lambda x: x.replace('_', ' ').title())
            top_factors_df['Impact %'] = (top_factors_df['impact'] * 100).round(3)
            top_factors_df['Effect'] = top_factors_df['impact'].apply(lambda x: "Favors Home" if x > 0 else "Favors Away")
            display_df = top_factors_df[['Feature', 'Impact %', 'Effect']]
            safe_dataframe(display_df, hide_index=True)

        # Pattern-Based Adjustments (NEW - from error analysis)
        if 'pattern_adjustments' in pred and pred['pattern_adjustments']:
            st.markdown("### üîß Smart Adjustments Applied")
            st.markdown("""
            <div style="background: #fef3c7; border-left: 4px solid #f59e0b; padding: 12px; border-radius: 4px; margin-bottom: 15px;">
            <b>‚ö° What are Smart Adjustments?</b><br>
            The AI detected patterns where the base prediction might be wrong. These adjustments are based on analysis of 94+ historical games where the model struggled.<br>
            <em>Think of it as the model saying: "I've seen this situation before and I was wrong - let me correct it."</em>
            </div>
            """, unsafe_allow_html=True)

            for adjustment in pred['pattern_adjustments']:
                if "Hot road team" in adjustment:
                    st.success(f"""
                    **‚úÖ {adjustment}**

                    **What it means**: The away team is on a 4+ game winning streak and the ELO rating gap is small (<100 points).

                    **Why it matters**: Historically, hot road teams in this situation win 60% of the time, even when the model slightly favors the home team. The model boosted the away team's win probability by 10% to account for momentum.

                    **Translation**: The away team is playing with confidence and momentum trumps slight rating disadvantages.
                    """)
                elif "Cold home team" in adjustment:
                    st.warning(f"""
                    **‚ö†Ô∏è {adjustment}**

                    **What it means**: The home team is on a 3+ game losing streak and the ELO rating gap is moderate (<150 points).

                    **Why it matters**: Teams in free fall lose 73% of games even at home. The model reduced the home team's win probability by 8% to account for poor form.

                    **Translation**: The home team is struggling badly and home court advantage doesn't overcome that slump.
                    """)
                elif "Heavy travel" in adjustment:
                    st.error(f"""
                    **üõ´ {adjustment}**

                    **What it means**: The away team traveled 2000+ miles (cross-country) and is playing on zero rest (back-to-back game).

                    **Why it matters**: This brutal schedule combination has a 100% historical loss rate. The model reduced the away team's win probability by 15% - a massive penalty.

                    **Translation**: Extreme fatigue from cross-country travel + no rest = expect a tired, sluggish performance.
                    """)
                elif "Large ELO" in adjustment:
                    st.info(f"""
                    **üìä {adjustment}**

                    **What it means**: The ELO rating difference between teams is very large (>200 points) - a big mismatch on paper.

                    **Why it matters**: The model historically had a 50% error rate in these "obvious favorite" games. It was overconfident. The adjustment reduces the favorite's probability by 5% to avoid overconfidence.

                    **Translation**: Even heavy favorites can lose - the model is being more cautious about blowout predictions.
                    """)
                elif "B2B penalty" in adjustment:
                    st.warning(f"""
                    **üò¥ {adjustment}**

                    **What it means**: The home team is playing on zero rest (back-to-back) while the away team is rested.

                    **Why it matters**: Fatigue matters even at home. The model reduced the home team's win probability by 6% to account for tired legs.

                    **Translation**: The home team might be sluggish in the 4th quarter when fresh legs matter most.
                    """)

        radar_fig = create_feature_radar_chart(features, ht, at)
        if radar_fig:
            st.markdown("### üéØ Team Comparison")
            st.markdown("""
            <div style="background: #f0fdf4; border-left: 4px solid #059669; padding: 12px; border-radius: 4px; margin-bottom: 15px;">
            <b>üìä Team Comparison Radar Chart:</b> This visualization compares key team metrics side-by-side. Values are normalized to a 0-100 scale for comparison.
            </div>
            """, unsafe_allow_html=True)
            safe_plotly_chart(radar_fig)

            # NEW: Advanced Metrics Chart (Off/Def Rating, Pace, 3pt defense)
            st.markdown("#### üéØ Advanced Metrics")
            st.info("üí° **Key Analytics**: Offensive/Defensive Ratings show efficiency per 100 possessions (better than PPG). Pace shows game tempo. 3P% Defense shows perimeter defense quality.")
            from src.explainability_viz import create_advanced_metrics_comparison, create_stats_comparison_bars, create_feature_categories_table, format_prediction_for_twitter, get_matchup_context
            advanced_fig = create_advanced_metrics_comparison(features, ht, at)
            if advanced_fig:
                safe_plotly_chart(advanced_fig)
            
            # Close matchup context
            matchup_context = get_matchup_context(features, ht, at)
            if matchup_context:
                st.markdown("---")
                st.markdown(matchup_context)
            
            # Twitter Post Button
            st.markdown("---")
            st.markdown("### üì± Post to Twitter")
            
            try:
                import tweepy
                from src.twitter_integration import (
                    load_credentials_from_env, setup_twitter_api,
                    format_prediction_tweet,
                    create_chart_image, post_tweet_with_image, create_twitter_thread
                )
                from src.explainability_viz import (
                    create_advanced_metrics_comparison,
                    create_comprehensive_dashboard_charts,
                    format_injury_tweet
                )
                import tempfile
                
                # Force reload from .env file FIRST (before loading credentials)
                import os
                from dotenv import load_dotenv
                load_dotenv(override=True)  # Force reload .env
                
                # Load credentials fresh from env (after reload)
                creds = load_credentials_from_env()
                
                # Get dry_run value directly from env (most current)
                dry_run = os.getenv("TW_DRY_RUN", "true").lower() in ("1", "true", "yes")
                
                # Generate tweet text (needed for both preview and posting)
                twitter_text = format_prediction_tweet(pred, features)
                
                # Preview section (using columns instead of expander to avoid nesting)
                preview_col1, preview_col2 = st.columns([3, 1])
                with preview_col1:
                    st.markdown("**üìù Preview Tweet**")
                with preview_col2:
                    show_preview = st.checkbox("Show Preview", key=f"show_preview_{ht}_{at}", value=False)
                
                if show_preview:
                    st.text_area("Tweet Text", twitter_text, height=150, key=f"preview_{ht}_{at}")
                    
                    # Generate preview chart
                    preview_fig = create_advanced_metrics_comparison(features, ht, at)
                    if preview_fig:
                        st.markdown("**Preview Chart:**")
                        st.plotly_chart(preview_fig, use_container_width=True)
                
                st.markdown("---")
                
                # Posting options
                # Use a stable key and store value in session_state to prevent expander collapse
                post_mode_key = f"post_mode_value_{ht}_{at}"
                if post_mode_key not in st.session_state:
                    st.session_state[post_mode_key] = "Thread (Multiple Charts)"  # Default to Thread

                post_mode = st.radio(
                    "Post Format:",
                    ["Thread (Multiple Charts)", "Single Tweet (Composite Image)"],  # Thread first
                    index=0 if st.session_state[post_mode_key] == "Thread (Multiple Charts)" else 1,
                    key=f"post_mode_{ht}_{at}"
                )
                st.session_state[post_mode_key] = post_mode
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("üöÄ Post to Twitter", key=f"post_twitter_{ht}_{at}"):
                        with st.spinner("Generating charts and posting..."):
                            try:
                                # Verify credentials before proceeding
                                if not all([creds.get('api_key'), creds.get('access_token')]):
                                    st.error("‚ùå Twitter credentials not fully loaded. Check your .env file.")
                                    st.info("üí° If you just updated your .env file, **restart Streamlit** to load new credentials.")
                                    return
                                
                                # Setup API clients - Use fresh client to avoid Streamlit caching issues
                                # This ensures we always use the latest credentials from .env
                                from src.twitter_integration import create_fresh_twitter_client
                                try:
                                    api_clients = create_fresh_twitter_client()
                                except Exception as e:
                                    st.error(f"‚ùå Failed to create Twitter client: {e}")
                                    return
                                
                                # Quick test: verify client can authenticate (test read permission)
                                test_client = api_clients.get("client_v2")
                                if not test_client:
                                    st.error("‚ùå Failed to create Twitter API client. Check your credentials.")
                                    return
                                
                                # Test if we can read (verifies credentials work)
                                try:
                                    me = test_client.get_me()
                                    st.info(f"‚úì Authenticated as: @{me.data.username}")
                                    
                                    # DEBUG: Show which credentials are being used (first 10 chars only)
                                    st.caption(f"üîë Using API Key: {creds.get('api_key', 'MISSING')[:10]}... | Access Token: {creds.get('access_token', 'MISSING')[:10]}...")
                                    
                                except tweepy.Unauthorized as auth_error:
                                    error_msg = (
                                        f"‚ùå 401 Unauthorized: Invalid credentials.\n\n"
                                        f"This usually means:\n"
                                        f"1. Access Token doesn't match the API Key/Secret\n"
                                        f"2. Tokens were copied incorrectly (check for extra spaces)\n"
                                        f"3. Tokens belong to a different Twitter App\n\n"
                                        f"üîß Fix:\n"
                                        f"1. Verify your API Key and Secret in .env match the app that generated the Access Token\n"
                                        f"2. In Twitter Developer Portal, go to your app ‚Üí Keys and tokens\n"
                                        f"3. Make sure you're using tokens from the SAME app\n"
                                        f"4. Regenerate Access Token and Secret if needed\n"
                                        f"5. Copy tokens carefully (no extra spaces)\n"
                                        f"6. Restart Streamlit after updating .env"
                                    )
                                    st.error(error_msg)
                                    st.error(f"Technical error: {auth_error}")
                                    return
                                except Exception as auth_error:
                                    st.error(f"‚ùå Authentication failed: {auth_error}")
                                    return
                                
                                # Generate all charts
                                temp_dir = tempfile.mkdtemp()
                                chart_paths = []
                                
                                if post_mode == "Single Tweet (Composite Image)":
                                    # Create comprehensive dashboard
                                    all_charts = create_comprehensive_dashboard_charts(pred, features, ht, at)
                                    
                                    # Export key charts
                                    key_charts = ['elo', 'ratings_l10', 'shooting_l10']
                                    for chart_name in key_charts:
                                        if chart_name in all_charts:
                                            chart_path = os.path.join(temp_dir, f"{chart_name}.png")
                                            create_chart_image(all_charts[chart_name], chart_path)
                                            chart_paths.append(chart_path)
                                    
                                    # Create composite
                                    if chart_paths:
                                        composite_path = os.path.join(temp_dir, "composite.png")
                                        from src.twitter_integration import create_composite_image
                                        create_composite_image(chart_paths, composite_path, rows=2, cols=2)
                                        
                                        # Post
                                        response = post_tweet_with_image(
                                            api_clients, twitter_text, composite_path,
                                            alt_text=f"NBA prediction charts: {at} @ {ht}",
                                            dry_run=dry_run
                                        )
                                        
                                        if dry_run:
                                            st.info("‚úÖ [DRY RUN] Would post to Twitter. Set TW_DRY_RUN=false in .env and restart Streamlit to actually post.")
                                        else:
                                            st.success("‚úÖ Posted to Twitter successfully!")
                                else:
                                    # Thread mode - Include ALL available charts
                                    all_charts = create_comprehensive_dashboard_charts(pred, features, ht, at)
                                    
                                    # Export ALL charts available
                                    chart_order = ['elo', 'elo_gauge', 'ratings_l10', 'shooting_l10', 'pace', 'splits', 'situational']
                                    exported_charts = []
                                    chart_names_exported = []
                                    
                                    for chart_name in chart_order:
                                        if chart_name in all_charts:
                                            chart_path = os.path.join(temp_dir, f"{chart_name}.png")
                                            try:
                                                create_chart_image(all_charts[chart_name], chart_path)
                                                exported_charts.append(chart_path)
                                                chart_names_exported.append(chart_name)
                                            except Exception as e:
                                                logger.warning(f"Failed to export chart {chart_name}: {e}")
                                    
                                    # Use the same format_twitter_thread method as daily_auto_prediction.py
                                    # Import the DailyPredictionAutomation class to use its format_twitter_thread method
                                    from daily_auto_prediction import DailyPredictionAutomation

                                    # Create a temporary DailyPredictionAutomation instance to use its format_twitter_thread method
                                    temp_daily = DailyPredictionAutomation(
                                        db_path=str(db_path),
                                        model_dir="models",
                                        dry_run=False
                                    )
                                    
                                    # Prepare prediction dict in the format expected by format_twitter_thread
                                    prediction_for_thread = {
                                        'home_team': ht,
                                        'away_team': at,
                                        'prediction': pred['prediction'],  # 'home' or 'away'
                                        'predicted_winner': ht if pred['prediction'] == 'home' else at,
                                        'predicted_team_name': ht if pred['prediction'] == 'home' else at,
                                        'confidence': pred['confidence'],
                                        'home_win_probability': pred['home_win_probability'],
                                        'away_win_probability': pred['away_win_probability'],
                                        'features': features,
                                        'home_team_id': st.session_state.predictor._get_team_id(ht),
                                        'away_team_id': st.session_state.predictor._get_team_id(at),
                                    }
                                    
                                    # Use the same format_twitter_thread method as daily prediction
                                    thread_texts_from_daily, thread_image_paths_from_daily = temp_daily.format_twitter_thread(prediction_for_thread)

                                    # NEW STRUCTURE (Dec 2024):
                                    # format_twitter_thread now returns:
                                    # Tweet 1: Main prediction (no image)
                                    # Tweet 2: THE EDGE (situational chart)
                                    # Tweet 3: RECENT FORM (ratings_l10 chart)
                                    # Tweet 4: KEY MATCHUP (ratings_l10 or shooting_l10, dynamic)
                                    # Tweet 5: SCHEDULE SPOT (situational chart)
                                    # Tweet 6: HOME/ROAD SPLITS (splits chart)
                                    # Tweet 7+: Smart Adjustments (no image) / CTA (no image)

                                    # The method already returns the correct image_paths, so we can use them directly!
                                    thread_texts = thread_texts_from_daily

                                    # Use the image paths from format_twitter_thread
                                    # If they're empty or failed, use our exported charts as fallback
                                    if thread_image_paths_from_daily and any(thread_image_paths_from_daily):
                                        # Use the paths from format_twitter_thread
                                        filtered_texts = thread_texts
                                        filtered_charts_with_none = thread_image_paths_from_daily
                                    else:
                                        # Fallback: map our exported charts to the new structure
                                        filtered_texts = thread_texts
                                        filtered_charts_with_none = []

                                        # NEW MAPPING for new thread structure:
                                        new_chart_mapping = [
                                            None,  # Tweet 1: Main prediction (no image)
                                            'situational',  # Tweet 2: THE EDGE
                                            'ratings_l10',  # Tweet 3: RECENT FORM
                                            'ratings_l10',  # Tweet 4: KEY MATCHUP (default to ratings, could be shooting)
                                            'situational',  # Tweet 5: SCHEDULE SPOT
                                            'splits',       # Tweet 6: HOME/ROAD SPLITS
                                        ]

                                        for i, tweet_text in enumerate(thread_texts):
                                            if i < len(new_chart_mapping):
                                                chart_name = new_chart_mapping[i]
                                                if chart_name and chart_name in chart_names_exported:
                                                    chart_idx_in_order = chart_order.index(chart_name)
                                                    if chart_idx_in_order < len(exported_charts):
                                                        filtered_charts_with_none.append(exported_charts[chart_idx_in_order])
                                                    else:
                                                        filtered_charts_with_none.append(None)
                                                else:
                                                    filtered_charts_with_none.append(None)
                                            else:
                                                # Tweets 7+ (Smart Adjustments, CTA) have no images
                                                filtered_charts_with_none.append(None)
                                    
                                    # Post thread (filtered_charts_with_none has None for first tweet, charts for others)
                                    response = create_twitter_thread(
                                        api_clients, filtered_texts, filtered_charts_with_none, dry_run=dry_run
                                    )
                                    
                                    if dry_run:
                                        st.info("‚úÖ [DRY RUN] Would post thread to Twitter. Set TW_DRY_RUN=false in .env and restart Streamlit to actually post.")
                                    else:
                                        # Extract tweet IDs from response
                                        tweet_ids = []
                                        tweet_urls = []
                                        for r in response:
                                            if isinstance(r, dict) and r.get('success'):
                                                tweet_id = r.get('tweet_id')
                                                if tweet_id:
                                                    tweet_ids.append(str(tweet_id))
                                                    tweet_urls.append(f"https://twitter.com/user/status/{tweet_id}")
                                        
                                        if tweet_ids:
                                            st.success(f"‚úÖ Posted thread with {len(response)} tweets to Twitter!")
                                            st.markdown(f"**Tweet IDs:** {', '.join(tweet_ids)}")
                                            if len(tweet_urls) > 0:
                                                st.markdown(f"**View tweets:**")
                                                for i, url in enumerate(tweet_urls, 1):
                                                    st.markdown(f"- Tweet {i}: {url}")
                                        else:
                                            st.warning("‚ö†Ô∏è Thread posted but could not extract tweet IDs. Check your Twitter account.")
                                            st.json(response)
                            
                            except Exception as e:
                                st.error(f"‚ùå Error posting to Twitter: {e}")
                                import traceback
                                st.code(traceback.format_exc())
                
                with col2:
                    if st.button("üíæ Download Text Only", key=f"download_twitter_{ht}_{at}"):
                        twitter_text = format_prediction_tweet(pred, features)
                        st.download_button(
                            "‚¨áÔ∏è Download",
                            data=twitter_text,
                            file_name=f"prediction_{ht.replace(' ', '_')}_{at.replace(' ', '_')}_{pred.get('game_date', 'today')}.txt",
                            mime="text/plain"
                        )
                
                # Show dry_run status (check actual value)
                actual_dry_run = os.getenv("TW_DRY_RUN", "true").lower() in ("1", "true", "yes")
                if actual_dry_run:
                    st.info("‚ö†Ô∏è **Dry Run Mode**: Tweets won't be posted. Set `TW_DRY_RUN=false` in your `.env` file and restart Streamlit to post.")
                else:
                    st.success("‚úÖ **Live Mode**: Tweets will be posted to Twitter!")
            
            except Exception as e:
                import traceback
                st.error(f"‚ö†Ô∏è Twitter integration error: {str(e)}")
                # Fallback to download
                try:
                    twitter_text = format_prediction_for_twitter(pred, features)
                    st.download_button(
                        "üì± Download for Twitter (Text Only)",
                        data=twitter_text,
                        file_name=f"prediction_{ht.replace(' ', '_')}_{at.replace(' ', '_')}_{pred.get('game_date', 'today')}.txt",
                        mime="text/plain"
                    )
                except:
                    pass

            # Add detailed statistics table
            st.markdown("#### üìã Detailed Statistics Comparison")
            
            # Show feature categories table in a more compact way
            feat_table = create_feature_categories_table(features, ht, at)
            if not feat_table.empty:
                # Group by category and show in expandable sections
                categories = feat_table['Category'].unique()
                
                # Create tabs for major categories
                if len(categories) > 3:
                    tab_names = ['Elo & Form', 'Splits & Situational', 'Head-to-Head']
                    tab1, tab2, tab3 = st.tabs(tab_names)
                    
                    with tab1:
                        # Elo, Recent Form (Last 10), Recent Form (Last 5)
                        display_df = feat_table[feat_table['Category'].isin(['Elo & Ratings', 'Recent Form (Last 10)', 'Recent Form (Last 5)'])]
                        if not display_df.empty:
                            # Remove Category column for cleaner display
                            display_df = display_df.drop(columns=['Category'])
                            safe_dataframe(display_df, hide_index=True)
                    
                    with tab2:
                        # Home/Away Splits, Situational
                        display_df = feat_table[feat_table['Category'].isin(['Home/Away Splits', 'Situational'])]
                        if not display_df.empty:
                            display_df = display_df.drop(columns=['Category'])
                            safe_dataframe(display_df, hide_index=True)
                    
                    with tab3:
                        # Head-to-Head with warning
                        st.warning("‚ö†Ô∏è **H2H Limitations**: (1) Limited data: only ~4 games/year between teams. (2) Games alternate home/away, reducing home-specific relevance. Use with caution.")
                        display_df = feat_table[feat_table['Category'] == 'Head-to-Head']
                        if not display_df.empty:
                            display_df = display_df.drop(columns=['Category'])
                            safe_dataframe(display_df, hide_index=True)
                else:
                    # If few categories, show all at once but more compact
                    # Use st.expander for each category
                    for category in categories:
                        with st.expander(f"üìä {category}", expanded=True):
                            cat_df = feat_table[feat_table['Category'] == category].copy()
                            cat_df = cat_df.drop(columns=['Category'])
                            safe_dataframe(cat_df, hide_index=True)
            
            # Show bar chart comparison
            bars_fig = create_stats_comparison_bars(features, ht, at)
            if bars_fig:
                st.markdown("#### üìä Side-by-Side Statistics")
                safe_plotly_chart(bars_fig)

        if 'base_model_predictions' in pred:
            st.markdown("### ü§ñ Model Consensus")
            st.info("üí° **Individual home win probabilities from each base model.** These show how each model independently predicts the home team's chance to win. The final prediction combines these with weighted averaging. Low percentages mean most models predict the away team will win - this is normal when the away team is favored.")
            cols = st.columns(4)
            model_names = {'xgboost': 'XGBoost', 'lightgbm': 'LightGBM', 'random_forest': 'Random Forest', 'logistic': 'Logistic'}
            final_home_prob = pred.get('home_win_probability', 0)
            for i, (name, prob) in enumerate(pred['base_model_predictions'].items()):
                display_name = model_names.get(name, name.title())
                # Show the home win probability with context
                cols[i].metric(
                    display_name, 
                    f"{prob:.1%}",
                    help=f"Home win probability: {prob:.1%}. Final ensemble prediction: {final_home_prob:.1%}"
                )

# =============================================================================
# HEADER & TABS
# =============================================================================
st.markdown("# üèÄ NBA Predictor")

tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(["Today", "Portfolio", "Analytics", "Train", "Performance", "Settings", "Twitter Status"])

# =============================================================================
# TAB 1: GAMES PREDICTIONS (with date picker)
# =============================================================================
with tab1:
    st.markdown("### üóìÔ∏è Select Date")
    col_date, col_btn = st.columns([2, 1])
    with col_date:
        selected_date = st.date_input(
            "Game Date",
            value=datetime.now().date(),
            min_value=datetime.now().date() - timedelta(days=7),
            max_value=datetime.now().date() + timedelta(days=14),
            help="Select a date to fetch games for that day"
        )
    with col_btn:
        st.write("")
        st.write("")
        fetch_button = st.button("üîÑ Fetch Games")

    if fetch_button:
        with st.spinner(f"Loading games for {selected_date.strftime('%Y-%m-%d')}..."):
            try:
                fetcher = NBADataFetcher(str(db_path))
                # Convert selected_date to string format
                date_str = selected_date.strftime('%Y-%m-%d')
                todays = fetcher.get_games_for_date(date_str)

                if todays.empty:
                    st.info(f"No games found for {date_str}")
                    st.session_state.todays_predictions = None
                else:
                    # Create list with game dates
                    games_with_dates = []
                    for _, g in todays.iterrows():
                        home = ID_TO_TEAM.get(g['home_team_id'])
                        away = ID_TO_TEAM.get(g['away_team_id'])
                        if home and away:
                            game_date = g.get('game_date', datetime.now().strftime('%Y-%m-%d'))
                            # Ensure game_date is a string in YYYY-MM-DD format
                            if isinstance(game_date, pd.Timestamp):
                                game_date = game_date.strftime('%Y-%m-%d')
                            elif not isinstance(game_date, str):
                                game_date = datetime.now().strftime('%Y-%m-%d')
                            games_with_dates.append((home, away, game_date))

                    if games_with_dates:
                        prog = st.progress(0)
                        status = st.empty()
                        preds = []

                        for i, (h, a, game_date) in enumerate(games_with_dates):
                            status.text(f"Analyzing {a} @ {h}...")
                            try:
                                p = st.session_state.predictor.predict_game(h, a, game_date=game_date)
                                if p and p.get('prediction'):
                                    p['home_team'] = h
                                    p['away_team'] = a
                                    p['game_date'] = game_date  # Store game date in prediction
                                    preds.append(p)
                                    save_prediction_to_db(str(db_path), {
                                        'game_date': game_date,  # Use actual game date, not today
                                        'home_team': h, 'away_team': a,
                                        'predicted_winner': h if p['prediction'] == 'home' else a,
                                        'predicted_home_prob': p['home_win_probability'],
                                        'predicted_away_prob': p['away_win_probability'],
                                        'confidence': p['confidence'],
                                        'features': p.get('features', {})
                                    })
                            except Exception as e:
                                error_msg = str(e)
                                st.warning(f"Error on {a} @ {h}: {error_msg}")
                                # Print full error for debugging
                                print(f"‚ùå Error on {a} @ {h}: {error_msg}")
                                import traceback
                                traceback.print_exc()
                            prog.progress((i + 1) / len(games_with_dates))

                        prog.empty()
                        status.empty()
                        st.session_state.todays_predictions = preds
                        if preds:
                            st.success(f"‚úÖ Analyzed {len(preds)} games! ({len(games_with_dates)} total games found)")
                            # Debug: Show which games were successfully predicted
                            if len(preds) < len(games_with_dates):
                                missing = len(games_with_dates) - len(preds)
                                st.warning(f"‚ö†Ô∏è {missing} game(s) failed to generate predictions. Check console for errors.")
                            
                            # Email report button
                            st.markdown("---")
                            col_email1, col_email2 = st.columns([3, 1])
                            with col_email1:
                                st.markdown("**üìß Envoyer le rapport par email**")
                            with col_email2:
                                if st.button("üìß Envoyer Email", key="send_email_report"):
                                    with st.spinner("Envoi du rapport par email..."):
                                        try:
                                            from src.email_reporter import EmailReporter
                                            email_reporter = EmailReporter(db_path=str(db_path))
                                            success = email_reporter.send_daily_report(test_mode=False)
                                            if success:
                                                st.success("‚úÖ Email envoy√© avec succ√®s!")
                                            else:
                                                st.error("‚ùå Erreur lors de l'envoi de l'email. V√©rifiez les logs.")
                                        except Exception as e:
                                            st.error(f"‚ùå Erreur: {str(e)[:100]}")
                        else:
                            st.warning("No predictions generated. Check if model is trained.")
            except Exception as e:
                st.error(f"Error: {e}")

    if st.session_state.todays_predictions:
        preds = st.session_state.todays_predictions
        st.markdown("### üìä Prediction Summary")
        c1, c2, c3 = st.columns(3)
        high_conf_count = sum(1 for p in preds if p['confidence'] >= 0.7)
        c1.metric("High Confidence", high_conf_count)
        avg_conf = np.mean([p['confidence'] for p in preds])
        c2.metric("Average Confidence", f"{avg_conf:.1%}")
        c3.metric("Total Games", len(preds))

        st.markdown("---")
        st.markdown("### üèÄ Game Predictions")
        if len(preds) == 0:
            st.warning("No predictions to display. Check if predictions were generated successfully.")
        else:
            for i, p in enumerate(sorted(preds, key=lambda x: x['confidence'], reverse=True)):
                try:
                    display_game(p, expanded=False)  # Never auto-expand to prevent scroll issues
                except Exception as e:
                    # If one game fails to display, show error but continue with others
                    game_name = f"{p.get('away_team', '?')} @ {p.get('home_team', '?')}"
                    st.error(f"Error displaying game {i+1} ({game_name}): {str(e)[:100]}")
                    import traceback
                    with st.expander(f"Error details for game {i+1}"):
                        st.code(traceback.format_exc())
                    continue  # Continue to next game
    elif st.session_state.todays_predictions is None:
        st.info("üëÜ Click 'üîÑ Fetch Today's Games' above to load predictions")

# =============================================================================
# TAB 2: PORTFOLIO
# =============================================================================
with tab2:
    st.markdown("## Portfolio")
    balance_info = get_user_balance(str(db_path))
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Balance", f"${balance_info['balance']:,.2f}")
    c2.metric("Wagered", f"${balance_info['wagered']:,.2f}")
    c3.metric("Won", f"${balance_info['won']:,.2f}")
    profit = balance_info['won'] - balance_info['lost']
    roi = (profit / balance_info['wagered'] * 100) if balance_info['wagered'] > 0 else 0
    c4.metric("ROI", f"{roi:+.1f}%")

    st.markdown("---")
    history = get_portfolio_history(str(db_path))
    if not history.empty:
        for _, bet in history.iterrows():
            games = json.loads(bet['games']) if isinstance(bet['games'], str) else bet['games']
            icon = {'pending': '‚è≥', 'won': '‚úÖ', 'lost': '‚ùå'}.get(bet['status'], '‚è≥')
            st.markdown(f"{icon} **{bet['bet_type'].upper()}**: {' + '.join([g['team'] for g in games])} | ${bet['stake']:.2f} @ {bet['combined_odds']:.2f}")
    else:
        st.info("No bets yet")

# =============================================================================
# TAB 3: TEAM ANALYTICS
# =============================================================================
with tab3:
    st.markdown("## Team Analytics")
    c1, c2 = st.columns(2)
    selected_team = c1.selectbox("Team", NBA_TEAMS)
    analysis = c2.selectbox("Type", ["Overview", "Injuries", "Head-to-Head"])

    if st.button("Load"):
        team_id = TEAM_IDS.get(selected_team)
        if team_id:
            with st.spinner("Loading..."):
                try:
                    fetcher = NBADataFetcher(str(db_path))
                    fe = FeatureEngineer(str(db_path))

                    if analysis == "Overview":
                        recent = fetcher.get_team_recent_games(team_id, n_games=15)
                        if not recent.empty:
                            is_home = recent['home_team_id'] == team_id
                            wins = sum((is_home & (recent['home_win'] == 1)) | (~is_home & (recent['home_win'] == 0)))
                            c1, c2, c3, c4 = st.columns(4)
                            c1.metric("Record", f"{wins}-{15-wins}")
                            c2.metric("Win %", f"{wins/15*100:.0f}%")
                            c3.metric("Elo", f"{fe.elo_system.get_rating(team_id):.0f}")
                            ppg = recent.apply(lambda x: x['home_score'] if x['home_team_id'] == team_id else x['away_score'], axis=1).mean()
                            c4.metric("PPG", f"{ppg:.1f}")

                            display_df = recent[['game_date', 'home_team', 'away_team', 'home_score', 'away_score']].copy()
                            display_df['W/L'] = recent.apply(lambda x: 'W' if ((x['home_team_id'] == team_id and x['home_win']) or (x['away_team_id'] == team_id and not x['home_win'])) else 'L', axis=1)
                            safe_dataframe(display_df)

                    elif analysis == "Injuries":
                        try:
                            tracker = InjuryTracker(str(db_path))
                            inj = tracker.get_team_injuries(team_id, force_refresh=True)
                            c1, c2 = st.columns(2)
                            c1.metric("Injured", inj['total_injured'])
                            c2.metric("Stars Out", "Yes" if inj['star_injured'] else "No")
                            if inj['injuries']:
                                for i in inj['injuries']:
                                    st.write(f"- {i['player']}: {i['injury']} ({i['status']})")
                            else:
                                st.success("No injuries reported")
                        except Exception as e:
                            st.warning(f"Could not fetch injuries: {e}")

                    elif analysis == "Head-to-Head":
                        opp = st.selectbox("Opponent", [t for t in NBA_TEAMS if t != selected_team], key="h2h_opponent_select")
                        opp_id = TEAM_IDS.get(opp)
                        if opp_id:
                            conn = sqlite3.connect(db_path)
                            h2h = pd.read_sql_query("""
                                SELECT game_date, home_team, away_team, home_score, away_score FROM games
                                WHERE (home_team_id = ? AND away_team_id = ?) OR (home_team_id = ? AND away_team_id = ?)
                                ORDER BY game_date DESC LIMIT 10
                            """, conn, params=(team_id, opp_id, opp_id, team_id))
                            conn.close()
                            if not h2h.empty:
                                safe_dataframe(h2h)
                            else:
                                st.info("No H2H games found")
                except Exception as e:
                    st.error(f"Error: {e}")

# =============================================================================
# TAB 4: TRAIN MODEL
# =============================================================================
with tab4:
    st.markdown("## Train Model")

    # Check if model exists by looking for required files
    models_path_check = project_root / "models"
    required_files = ['meta_model.pkl', 'scaler.pkl', 'feature_names.json']
    model_files_exist = all((models_path_check / f).exists() for f in required_files)
    
    if model_files_exist:
        import os
        # Get the most recent file modification time as the training date
        file_times = []
        for f in required_files:
            file_path = models_path_check / f
            if file_path.exists():
                file_times.append(os.path.getmtime(file_path))
        if file_times:
            mt = datetime.fromtimestamp(max(file_times))
            st.success(f"‚úÖ Model found! Last trained: {mt.strftime('%Y-%m-%d %H:%M')}")
            
            # Verify model can actually be loaded
            try:
                test_predictor = NBAPredictor(db_path=str(db_path), model_dir=str(models_path))
                if test_predictor.load_model():
                    st.info(f"‚úì Model successfully loaded and ready for predictions")
                else:
                    st.warning("‚ö†Ô∏è Model files exist but could not be loaded. May need retraining.")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Model files exist but error loading: {str(e)[:100]}")
    else:
        st.warning("No model found - train first!")
        st.info("üí° The model consists of multiple files. Make sure to train using the button below.")

    c1, c2 = st.columns(2)
    start_yr = c1.selectbox("Start", [2022, 2023, 2024], index=2)  # Default to 2024
    end_yr = c2.selectbox("End", [2023, 2024, 2025], index=2)

    st.info("üí° **Tip**: Using only recent seasons (2024-2025) trains faster and focuses on current team dynamics. Older data may be less relevant due to roster changes.")

    if st.button("üöÄ Train Model"):
        st.warning("This takes 5-15 minutes...")
        prog = st.progress(0)
        status = st.empty()
        log = st.empty()
        t0 = time.time()

        try:
            from src.data_fetcher import NBADataFetcher, EloRatingSystem, FeatureEngineer
            from src.models import StackedEnsembleModel

            # Step 1: Fetch
            status.text("üì• Step 1/4: Fetching games...")
            fetcher = NBADataFetcher(str(db_path))
            seasons = [f"{yr}-{str(yr+1)[-2:]}" for yr in range(start_yr, end_yr + 1)]
            log.write(f"Seasons: {seasons}")
            games = fetcher.fetch_historical_games(seasons)
            log.write(f"‚úÖ Fetched {len(games)} games ({time.time()-t0:.0f}s)")
            prog.progress(25)

            # Step 2: Elo
            status.text("üìä Step 2/4: Calculating Elo ratings...")
            elo = EloRatingSystem(str(db_path))
            games_sorted = games.sort_values('game_date')
            total = len(games_sorted)

            for team in teams.get_teams():
                elo.ratings[team['id']] = elo.INITIAL_ELO

            elo_prog = st.progress(0)
            for idx, (_, row) in enumerate(games_sorted.iterrows()):
                elo.update_ratings(row['home_team_id'], row['away_team_id'], row['home_score'], row['away_score'], row['game_id'])
                if idx % 200 == 0:
                    elo_prog.progress(idx / total)
                    log.write(f"Elo: {idx}/{total} games... ({time.time()-t0:.0f}s)")
            elo_prog.empty()
            log.write(f"‚úÖ Elo complete ({time.time()-t0:.0f}s)")
            prog.progress(45)

            # Step 3: Features
            status.text("üîß Step 3/4: Engineering features...")
            log.write("Creating features (no injuries/odds for speed)...")
            log.write("‚è≥ This may take 1-3 minutes depending on data size...")
            fe = FeatureEngineer(str(db_path))
            fe.enhanced_features_available = False  # Disable slow external APIs
            X, y, sample_weights = fe.create_training_dataset(games)
            log.write(f"‚úÖ {len(X)} samples, {len(X.columns)} features")
            log.write(f"üìä Sample weights calculated (recent games weighted {sample_weights[-100:].mean():.2f}x vs old {sample_weights[:100].mean():.2f}x)")
            log.write(f"‚è±Ô∏è Feature engineering: {time.time()-t0:.0f}s")
            prog.progress(65)

            # Step 4: Train
            status.text("ü§ñ Step 4/4: Training model with recency weighting...")
            log.write("‚è≥ Training ensemble (XGBoost, LightGBM, RandomForest, Logistic)...")
            log.write("üìà Using 5-fold time-series cross-validation...")
            model = StackedEnsembleModel()
            results = model.train(X, y, sample_weights=sample_weights, n_splits=5)
            acc = results['mean_cv_accuracy']
            log.write(f"‚úÖ Trained! CV Accuracy: {acc:.1%} ¬± {results['std_cv_accuracy']:.1%} ({time.time()-t0:.0f}s)")
            prog.progress(90)

            # Save
            model.save(str(project_root / "models"))
            prog.progress(100)
            st.success(f"‚úÖ Done! Accuracy: {acc:.1%} ¬± {results['std_cv_accuracy']:.1%} | Time: {(time.time()-t0)/60:.1f} min")

            st.session_state.predictor = NBAPredictor(db_path=str(db_path), model_dir=str(models_path))

        except Exception as e:
            st.error(f"Failed: {e}")
            import traceback
            st.code(traceback.format_exc())

# =============================================================================
# TAB 5: PERFORMANCE
# =============================================================================
with tab5:
    st.markdown("## Performance")

    col1, col2 = st.columns([3, 1])
    with col1:
        lookback = st.slider("Lookback Days", min_value=0, max_value=30, value=7, help="How many days back to check for game results")
    with col2:
        st.write("")  # Spacing
        st.write("")  # Spacing

    st.markdown("---")

    col_update1, col_update2 = st.columns(2)
    with col_update1:
        if st.button("üîÑ 1. Refresh Game Data", key="perf_refresh_games"):
            with st.spinner("Fetching recent games from NBA API..."):
                try:
                    from nba_api.stats.endpoints import leaguegamefinder
                    from nba_api.stats.static import teams as nba_teams
                    
                    # Fetch recent games using leaguegamefinder (more reliable)
                    end_date = datetime.now()
                    start_date = end_date - timedelta(days=7)
                    
                    date_from = start_date.strftime('%m/%d/%Y')
                    date_to = end_date.strftime('%m/%d/%Y')
                    
                    status_text = st.empty()
                    status_text.text(f"Fetching games from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}...")
                    
                    # Fetch all recent games
                    time.sleep(0.6)
                    finder = leaguegamefinder.LeagueGameFinder(
                        date_from_nullable=date_from,
                        date_to_nullable=date_to,
                        season_type_nullable='Regular Season',
                        league_id_nullable='00'  # NBA
                    )
                    
                    games_df = finder.get_data_frames()[0]
                    
                    if games_df.empty:
                        st.warning("No games found from NBA API")
                    else:
                        st.info(f"üìã Found {len(games_df)} game entries from API")
                        
                        # Process and save games to database
                        conn_temp = sqlite3.connect(str(db_path))
                        fetched = 0
                        
                        # Group by GAME_ID to get both teams' stats
                        team_map = {t['id']: t for t in nba_teams.get_teams()}
                        
                        for game_id, game_group in games_df.groupby('GAME_ID'):
                            if len(game_group) != 2:
                                continue  # Need both teams
                                
                            # Determine home and away from matchup string
                            row1, row2 = game_group.iloc[0], game_group.iloc[1]
                            
                            # "vs." means home, "@" means away
                            if 'vs.' in str(row1.get('MATCHUP', '')):
                                home_row, away_row = row1, row2
                            else:
                                home_row, away_row = row2, row1
                            
                            home_pts = home_row.get('PTS')
                            away_pts = away_row.get('PTS')
                            
                            if pd.isna(home_pts) or pd.isna(away_pts) or home_pts == 0:
                                continue  # Game not finished
                            
                            game_date_str = str(home_row.get('GAME_DATE', ''))[:10]  # Get YYYY-MM-DD
                            home_team_id = home_row.get('TEAM_ID')
                            away_team_id = away_row.get('TEAM_ID')
                            
                            home_team_info = team_map.get(home_team_id, {})
                            away_team_info = team_map.get(away_team_id, {})
                            
                            try:
                                conn_temp.execute("""
                                    INSERT OR REPLACE INTO games (
                                        game_id, game_date, home_team_id, away_team_id,
                                        home_team, away_team, home_score, away_score, home_win
                                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                                """, (
                                    game_id,
                                    game_date_str,
                                    home_team_id,
                                    away_team_id,
                                    home_team_info.get('abbreviation', str(home_team_id)),
                                    away_team_info.get('abbreviation', str(away_team_id)),
                                    int(home_pts),
                                    int(away_pts),
                                    1 if home_pts > away_pts else 0
                                ))
                                fetched += 1
                            except Exception as e:
                                print(f"Error saving game {game_id}: {e}")
                                continue
                        
                        conn_temp.commit()
                        conn_temp.close()
                        status_text.empty()
                        
                        if fetched > 0:
                            st.success(f"‚úÖ Fetched {fetched} games from last 7 days!")
                            safe_rerun()
                        else:
                            st.info("No new finished games found")
                except Exception as e:
                    st.error(f"Error: {e}")
                    import traceback
                    st.code(traceback.format_exc())
    
    with col_update2:
        if st.button("‚úÖ 2. Update Results", key="perf_update_results"):
            with st.spinner("Matching predictions to game results..."):
                try:
                    fb = ModelFeedbackSystem(str(db_path))
                    updated = fb.update_predictions_with_results(lookback_days=lookback, use_api=False)
                    fb.close()
                    
                    if updated > 0:
                        st.success(f"‚úÖ Updated {updated} predictions!")
                        safe_rerun()
                    else:
                        st.warning("No matches found. Make sure you clicked 'Refresh Game Data' first.")
                except Exception as e:
                    st.error(f"Error: {e}")

    try:
        fb = ModelFeedbackSystem(str(db_path))
        try:
            perf = fb.evaluate_model_performance(period_days=30)
            if perf and perf.get('total_predictions', 0) > 0:
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("Accuracy", f"{perf.get('accuracy',0)*100:.1f}%")
                c2.metric("Predictions", perf.get('total_predictions', 0))
                c3.metric("Correct", perf.get('correct_predictions', 0))
                c4.metric("Brier Score", f"{perf.get('brier_score', 0):.4f}")
            else:
                st.info("No verified predictions yet")
        except:
            st.info("Make predictions and update results to see performance")

        # Show all recent predictions with better date filtering
        conn = sqlite3.connect(str(db_path))
        cutoff_date = (datetime.now() - timedelta(days=lookback)).strftime('%Y-%m-%d')
        today_str = datetime.now().strftime('%Y-%m-%d')

        recent = pd.read_sql_query("""
            SELECT game_date, home_team, away_team, predicted_winner, confidence,
                   CASE WHEN correct = 1 THEN '‚úÖ' WHEN correct = 0 THEN '‚ùå' ELSE '‚è≥' END as result,
                   prediction_date, actual_winner
                FROM predictions
            WHERE game_date >= ? AND game_date <= ?
            ORDER BY game_date DESC, prediction_date DESC
            LIMIT 50
        """, conn, params=(cutoff_date, today_str))
        conn.close()

        if not recent.empty:
            st.markdown(f"### Recent Predictions (Last {lookback} Days)")
            # Add helpful columns
            recent['Days Ago'] = recent['game_date'].apply(lambda x: (datetime.now().date() - datetime.strptime(x, '%Y-%m-%d').date()).days if pd.notna(x) else None)
            
            # Reorder columns for better readability
            display_cols = ['game_date', 'Days Ago', 'home_team', 'away_team', 'predicted_winner', 
                          'confidence', 'result', 'actual_winner']
            display_cols = [c for c in display_cols if c in recent.columns]
            safe_dataframe(recent[display_cols].rename(columns={
                'game_date': 'Game Date',
                'Days Ago': 'Days Ago',
                'home_team': 'Home',
                'away_team': 'Away',
                'predicted_winner': 'Predicted Winner',
                'confidence': 'Confidence',
                'result': 'Result',
                'actual_winner': 'Actual Winner'
            }), hide_index=True)
            
            # Summary stats
            total = len(recent)
            pending = len(recent[recent['result'] == '‚è≥'])
            correct = len(recent[recent['result'] == '‚úÖ'])
            wrong = len(recent[recent['result'] == '‚ùå'])
            
            st.markdown(f"**Summary**: {total} predictions | ‚úÖ {correct} correct | ‚ùå {wrong} wrong | ‚è≥ {pending} pending")
            
            # Show diagnostic info for pending predictions older than today
            if pending > 0:
                past_pending = recent[(recent['result'] == '‚è≥') & (recent['Days Ago'] > 0)]
                if len(past_pending) > 0:
                    with st.expander(f"‚ö†Ô∏è {len(past_pending)} past games still pending - click to diagnose"):
                        st.markdown("""
                        **These predictions are for games that should have finished but results weren't found.**
                        
                        **Possible reasons:**
                        1. **Wrong matchup**: The predicted game might not exist on that date
                        2. **Team name mismatch**: Database uses different team names than predictions
                        3. **Game data not in DB**: Need to refresh game data first
                        
                        **Try these steps:**
                        1. Click **"üîÑ Refresh Game Data"** to fetch recent games
                        2. Then click **"üîÑ Update Results from NBA API"** again
                        """)
                        
                        # Show what games exist in DB for these dates
                        st.markdown("**Games in database for these dates:**")
                        conn_diag = sqlite3.connect(str(db_path))
                        for _, row in past_pending.iterrows():
                            gdate = row['game_date']
                            games_on_date = pd.read_sql_query("""
                                SELECT home_team, away_team, home_score, away_score 
                                FROM games WHERE game_date = ?
                            """, conn_diag, params=(gdate,))
                            if not games_on_date.empty:
                                st.write(f"**{gdate}**: {len(games_on_date)} games found")
                                st.caption(", ".join([f"{r['away_team']}@{r['home_team']}" for _, r in games_on_date.iterrows()]))
                            else:
                                st.write(f"**{gdate}**: ‚ùå No games in database")
                        conn_diag.close()
                        
                        # Option to clear invalid predictions
                        if st.button("üóëÔ∏è Clear Old Pending Predictions", key="clear_invalid_preds"):
                            try:
                                conn_del = sqlite3.connect(str(db_path))
                                # Delete predictions where game_date < today and result is still pending
                                today_str = datetime.now().strftime('%Y-%m-%d')
                                conn_del.execute("""
                                    DELETE FROM predictions 
                                    WHERE game_date < ? AND actual_winner IS NULL
                                """, (today_str,))
                                conn_del.commit()
                                deleted = conn_del.total_changes
                                conn_del.close()
                                st.success(f"‚úÖ Cleared {deleted} old pending predictions. Refresh to see changes.")
                                safe_rerun()
                            except Exception as e:
                                st.error(f"Error clearing predictions: {e}")
        else:
            # Check if there are ANY predictions at all
            conn = sqlite3.connect(str(db_path))
            total_count = pd.read_sql_query("SELECT COUNT(*) as count FROM predictions", conn)
            conn.close()
            if total_count.iloc[0]['count'] > 0:
                st.info(f"No predictions found in the last {lookback} days. Try increasing the lookback period or check if predictions are being saved with the correct game dates.")
            else:
                st.info("No predictions found in database. Make some predictions first!")
        fb.close()
    except Exception as e:
        st.error(f"Error: {e}")

# =============================================================================
# TAB 6: SETTINGS
# =============================================================================
with tab6:
    st.markdown("## Settings")

    c1, c2 = st.columns(2)
    if c1.button("Init Database"):
        init_database(str(db_path))
        st.success("Done!")

    if c2.button("Update Results", key="settings_update_results"):
        with st.spinner("Updating predictions..."):
            try:
                fb = ModelFeedbackSystem(str(db_path))
                n = fb.update_predictions_with_results(lookback_days=30)
                fb.close()
                if n > 0:
                    st.success(f"‚úÖ Updated {n} predictions")
                else:
                    st.info(f"‚ÑπÔ∏è No predictions updated. Check if games have been played and are in the database.")
            except Exception as e:
                st.error(f"Error: {e}")

    st.markdown("---")
    st.markdown("""
    **Model:** XGBoost + LightGBM + Random Forest + Logistic Regression

    **Features (84+):** Elo, Recent Form, H2H, Rest Days, Streaks, Travel, Injuries

    **Feedback Loop:** Predictions saved ‚Üí Results fetched ‚Üí Performance tracked ‚Üí Retrain when needed
    """)

# =============================================================================
# TAB 7: TWITTER STATUS (24-Hour Rate Limits)
# =============================================================================
with tab7:
    st.markdown("## üê¶ Twitter Rate Limits")
    st.caption("Free Tier: 17 tweets per 24 hours")

    if st.button("üîÑ Check Status"):
        try:
            from src.twitter_rate_limits import (
                get_cached_rate_limits, 
                format_rate_limit_display,
                get_24h_rate_limits_from_api
            )
            from src.twitter_integration import create_fresh_twitter_client

            with st.spinner("Checking rate limits..."):
                # Try to get fresh data from API
                try:
                    api_clients = create_fresh_twitter_client()
                    client_v2 = api_clients.get("client_v2")
                    api_v1 = api_clients.get("api_v1")
                    if client_v2:
                        limits = get_24h_rate_limits_from_api(client_v2, api_v1)
                        if limits:
                            source = limits.get('source', 'unknown')
                            st.success(f"‚úÖ Fetched fresh rate limit data (source: {source})")
                except Exception as api_error:
                    st.info(f"Could not fetch fresh data: {api_error}")
                    limits = None

                # Fallback to cache if API call didn't return data
                if not limits:
                    limits = get_cached_rate_limits()
                    if limits:
                        st.info("üìã Using cached data (may be up to 1 hour old)")

            if limits:
                formatted = format_rate_limit_display(limits)

                # Overall status
                if formatted['can_post']:
                    st.success("‚úÖ Can post tweets")
                else:
                    st.error("üî¥ Rate limit exhausted")

                # Single row with key info
                col1, col2, col3 = st.columns(3)

                app = formatted['app_24h']
                user = formatted['user_24h']

                with col1:
                    st.metric("APP Limit", f"{app['remaining']}/{app['limit']}")

                with col2:
                    st.metric("USER Limit", f"{user['remaining']}/{user['limit']}")

                with col3:
                    hours = app['hours_until_reset']
                    if hours > 0:
                        # Format as hours and minutes
                        h = int(hours)
                        m = int((hours - h) * 60)
                        if h > 0 and m > 0:
                            reset_str = f"{h}h {m} mins"
                        elif h > 0:
                            reset_str = f"{h}h"
                        else:
                            reset_str = f"{m} mins"
                        st.metric("Resets in", reset_str)
                    else:
                        st.metric("Resets", "Now")

                st.caption(f"Reset time: {app['reset_time']}")

            else:
                st.warning("‚ö†Ô∏è No rate limit data available")
                st.info("""
                **üìù Note about Twitter API v2 Rate Limits:**
                
                Twitter's API v2 only exposes 24-hour rate limit headers (showing remaining tweets) 
                when you **hit the rate limit** (429 error), not in successful responses.
                
                This means:
                - ‚úÖ **"No data available" = You can post** (not rate limited)
                - üî¥ **If you see data = You hit the limit** (rate limited)
                
                Free tier allows **17 tweets per 24 hours**. The API won't show your exact 
                remaining count until you hit the limit. This is a limitation of Twitter's API, 
                not a bug in this app.
                
                You can safely post tweets as long as you see "No data available" - it means 
                you haven't hit the 17-tweet daily limit yet.
                """)

        except Exception as e:
            st.error(f"Error: {e}")
    else:
        st.info("üëÜ Click to check your current Twitter API rate limits")

st.caption("NBA Predictor v2.1")
